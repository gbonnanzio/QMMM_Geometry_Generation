{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gbonn\\anaconda3\\envs\\md-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import MDAnalysis as mda\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.optimize import minimize\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gbonn\\anaconda3\\envs\\md-env\\Lib\\site-packages\\MDAnalysis\\coordinates\\PDB.py:777: UserWarning: Unit cell dimensions not found. CRYST1 record set to unitary values.\n",
      "  warnings.warn(\"Unit cell dimensions not found. \"\n",
      "c:\\Users\\gbonn\\anaconda3\\envs\\md-env\\Lib\\site-packages\\MDAnalysis\\coordinates\\PDB.py:1153: UserWarning: Found no information for attr: 'formalcharges' Using default value of '0'\n",
      "  warnings.warn(\"Found no information for attr: '{}'\"\n",
      "c:\\Users\\gbonn\\anaconda3\\envs\\md-env\\Lib\\site-packages\\MDAnalysis\\coordinates\\PDB.py:1200: UserWarning: Found missing chainIDs. Corresponding atoms will use value of 'X'\n",
      "  warnings.warn(\"Found missing chainIDs.\"\n"
     ]
    }
   ],
   "source": [
    "# read in each of the substrate files\n",
    "directory = 'substrate_files/'\n",
    "file_names = [f for f in os.listdir(directory) if \"_head\" not in f]\n",
    "\n",
    "for curr_file_name in file_names:\n",
    "    file_start = curr_file_name.split('.')[0]\n",
    "    # load substrate universe\n",
    "    substrate = mda.Universe(directory+curr_file_name)\n",
    "    # identify the atoms that comprise the aka substrates \n",
    "    substrate_important_indexes = get_substrate_aka_indexes(substrate)\n",
    "    selected_atoms = substrate.atoms[list(substrate_important_indexes.values())]\n",
    "    selected_atoms.write(directory + file_start + \"_head.pdb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C2': 1, 'O1': 12, 'C3': 0, 'O2': 11, 'O3': 9, 'R': 2}\n",
      "{'C1': 1, 'N1': 2, 'S1': 0, 'N2': 20}\n"
     ]
    }
   ],
   "source": [
    "substrate_6 = mda.Universe(directory + '6.pdb')\n",
    "substrate_6_important_indexes = get_substrate_aka_indexes(substrate_6)\n",
    "print(substrate_6_important_indexes)\n",
    "\n",
    "receptor = mda.Universe('int1_receptor.pdb')\n",
    "ThDP_important_indexes = get_ThDP_indexes(receptor)\n",
    "print(ThDP_important_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atom_objective(point, centers, radii):\n",
    "    return sum((np.linalg.norm(point - center) - radius)**2 for center, radius in zip(centers, radii))\n",
    "\n",
    "def combined_objective(all_points, centers, radii):\n",
    "    # Split all_points into the three key points\n",
    "    C2, C3, O1 = np.split(all_points, len(all_points)/3)\n",
    "    \n",
    "    # Calculate atom-level errors for each point to fit them to sphere constraints\n",
    "    atom_err_C2 = atom_objective(C2, centers, radii[0])\n",
    "    atom_err_C3 = atom_objective(C3, centers, radii[1])\n",
    "    atom_err_O1 = atom_objective(O1, centers, radii[2])\n",
    "    \n",
    "    total_atom_err = atom_err_C2 + atom_err_C3 + atom_err_O1\n",
    "    \n",
    "    # Combine errors with weighting factors\n",
    "    return  total_atom_err \n",
    "\n",
    "def optimize_points(centers, initial_guess, radii):\n",
    "    # Flatten initial guess as midpoint of each set of centers\n",
    "    # Set up optimization\n",
    "    tolerance = 1e-6\n",
    "    result = minimize(\n",
    "        combined_objective,\n",
    "        initial_guess,\n",
    "        args=(centers, radii),\n",
    "        tol=tolerance\n",
    "    )\n",
    "    C2, C3, O1 = np.split(result.x, 3)\n",
    "    # Check for successful optimization\n",
    "    if result.success or result.fun < tolerance:\n",
    "        print('CONVERGED')\n",
    "    else:\n",
    "        print('NOT CONVERGED')\n",
    "    return C2, C3, O1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-34.66339  -36.011883  22.165665]\n"
     ]
    }
   ],
   "source": [
    "tpp_residue = receptor.select_atoms(\"resname TPP\")\n",
    "\n",
    "C1_coords = get_atom_position(tpp_residue,ThDP_important_indexes['C1'])\n",
    "N1_coords = get_atom_position(tpp_residue,ThDP_important_indexes['N1'])\n",
    "N2_coords = get_atom_position(tpp_residue,ThDP_important_indexes['N2'])\n",
    "S1_coords = get_atom_position(tpp_residue,ThDP_important_indexes['S1'])\n",
    "\n",
    "vector_S1_to_C1 = C1_coords - S1_coords\n",
    "vector_N1_to_C1 = C1_coords - N1_coords\n",
    "avg_vector = (vector_S1_to_C1 + vector_N1_to_C1)/2\n",
    "unit_vector = avg_vector / np.linalg.norm(avg_vector)\n",
    "guess_C2 = C1_coords + unit_vector * 1.54\n",
    "\n",
    "\n",
    "print(guess_C2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-34.894 -35.257  23.488]\n",
      " [-33.783 -34.924  24.16 ]\n",
      " [-33.487 -33.076  21.57 ]\n",
      " [-36.272 -34.716  24.347]]\n",
      "NOT CONVERGED\n",
      "Optimized points: [-34.95322067 -36.05735187  22.17123387] [-34.57322144 -37.59150683  22.56317159] [-34.04892146 -35.57772853  21.2669495 ]\n",
      "CONVERGED\n",
      "Reoptimized points: [-34.94014025 -36.07518795  22.18527961] [-34.57235262 -37.60205263  22.58615327] [-34.04679877 -35.58955324  21.27459049]\n"
     ]
    }
   ],
   "source": [
    "# Example input\n",
    "# ThDP C1, N1, N2, S1 atom coords\n",
    "centers = np.array([C1_coords,N1_coords,N2_coords,S1_coords])\n",
    "print(centers)\n",
    "# radii are in order of (columns) C1, N1, N2, S1 and then rows (C2, C3, O1) \n",
    "radii = [\n",
    "    [1.539,2.562,3.389,2.880],\n",
    "    [2.533,3.205,4.764,3.784],\n",
    "    [2.393,2.973,2.592,3.893]\n",
    "]\n",
    "#initial_guess = np.hstack([np.mean(centers, axis=0) for i in range(3)])\n",
    "initial_guess = np.hstack([guess_C2 for i in range(3)])\n",
    "#print(init)\n",
    "C2_optimized, C3_optimized, O1_optimized = optimize_points(centers, initial_guess, radii)\n",
    "all_optimized = [C2_optimized, C3_optimized, O1_optimized]\n",
    "print(\"Optimized points:\", C2_optimized, C3_optimized, O1_optimized)\n",
    "\n",
    "C2_err = atom_objective(C2_optimized, centers, radii[0])\n",
    "C3_err = atom_objective(C3_optimized, centers, radii[1])\n",
    "O1_err = atom_objective(O1_optimized, centers, radii[2])\n",
    "\n",
    "all_errors = [C2_err,C3_err,O1_err]\n",
    "min_error_index = all_errors.index(min(all_errors))\n",
    "redo_initial_guess = np.hstack([all_optimized[min_error_index] for i in range(3)])\n",
    "\n",
    "C2_reoptimized, C3_reoptimized, O1_reoptimized = optimize_points(centers, redo_initial_guess, radii)\n",
    "print(\"Reoptimized points:\", C2_reoptimized, C3_reoptimized, O1_reoptimized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_positions = [get_atom_position(substrate_6,substrate_6_important_indexes['C2']),get_atom_position(substrate_6,substrate_6_important_indexes['C3']),get_atom_position(substrate_6,substrate_6_important_indexes['O1'])]\n",
    "final_positions = [C2_reoptimized, C3_reoptimized, O1_reoptimized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "R, t = kabsch_algorithm(initial_positions,final_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-37.90549569, -33.33337875,  23.36411089])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_coords = []\n",
    "for atom_coords in substrate_6.atoms.positions:\n",
    "    new_coords = np.dot(R, atom_coords) + t\n",
    "    transformed_coords.append(new_coords)\n",
    "\n",
    "substrate_6.atoms.positions = transformed_coords\n",
    "\n",
    "# Save the updated universe to a new PDB file\n",
    "output_filename = \"aligned_substrate_6.pdb\"\n",
    "substrate_6.atoms.write(output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "C2_coords = substrate_6.atoms.positions[substrate_6_important_indexes['C2']]\n",
    "O1_coords = substrate_6.atoms.positions[substrate_6_important_indexes['O1']]\n",
    "C3_coords = substrate_6.atoms.positions[substrate_6_important_indexes['C3']]\n",
    "R_coords = substrate_6.atoms.positions[substrate_6_important_indexes['R']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angle(coord1,coord2,coord3):\n",
    "        # Calculate vectors BA and BC\n",
    "        BA = coord1 - coord2\n",
    "        BC = coord3 - coord2\n",
    "\n",
    "        # Compute the dot product and magnitudes of BA and BC\n",
    "        dot_product = np.dot(BA, BC)\n",
    "        magnitude_BA = np.linalg.norm(BA)\n",
    "        magnitude_BC = np.linalg.norm(BC)\n",
    "\n",
    "        # Calculate the cosine of the angle\n",
    "        cos_theta = dot_product / (magnitude_BA * magnitude_BC)\n",
    "\n",
    "        # Handle potential floating-point errors\n",
    "        cos_theta = np.clip(cos_theta, -1.0, 1.0)\n",
    "\n",
    "        # Calculate the angle in radians and then convert to degrees\n",
    "        angle_radians = np.arccos(cos_theta)\n",
    "        angle_degrees = np.degrees(angle_radians)\n",
    "\n",
    "        return angle_degrees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1_coords\n",
    "N1_coords\n",
    "N2_coords\n",
    "S1_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle_objective(atom1,atom2,atom3,angle):\n",
    "    angle_err = abs(get_angle(atom1,atom2,atom3) - angle)\n",
    "    return angle_err\n",
    "\n",
    "def combined_angle_objective(tail_coord, C1_coord, C2_coord, O1_coord, C3_coord, angles):\n",
    "    # Calculate atom-level errors for each point to fit them to sphere constraints\n",
    "    angle_err_C1_C2_R = angle_objective(C1_coord, C2_coord, tail_coord, angles[0])\n",
    "    angle_err_O1_C2_R = angle_objective(O1_coord, C2_coord, tail_coord, angles[1])\n",
    "    angle_err_C3_C2_R = angle_objective(C3_coord, C2_coord, tail_coord, angles[2])\n",
    "    \n",
    "    #dist_err = get_dist()\n",
    "\n",
    "    total_angle_err = angle_err_C1_C2_R + angle_err_O1_C2_R + angle_err_C3_C2_R\n",
    "    # Combine errors with weighting factors\n",
    "    return  total_angle_err \n",
    "\n",
    "def optimize_angles(angles,initial_guess):\n",
    "    # Flatten initial guess as midpoint of each set of centers\n",
    "    # Set up optimization\n",
    "    tolerance = 1e-6\n",
    "    max_dist = 1.382\n",
    "    bounds = [(C2_coords[0]-max_dist,C2_coords[0]+max_dist),(C2_coords[1]-max_dist,C2_coords[1]+max_dist),(C2_coords[2]-max_dist,C2_coords[2]+max_dist)]\n",
    "    result = minimize(\n",
    "        combined_angle_objective,\n",
    "        initial_guess,\n",
    "        args=(C1_coords,C2_coords,O1_coords,C3_coords,angles),\n",
    "        tol=tolerance,\n",
    "        bounds=bounds\n",
    "    )\n",
    "    \n",
    "    # Check for successful optimization\n",
    "    if result.success or result.fun < tolerance:\n",
    "        print('CONVERGED')\n",
    "    else:\n",
    "        print('NOT CONVERGED')\n",
    "    \n",
    "    return result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT CONVERGED\n"
     ]
    }
   ],
   "source": [
    "R_coord_guess = optimize_angles([111.1,110.2,107.5],R_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_R = R_coord_guess-R_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transformed_coords = []\n",
    "for atom_coords in substrate_6.atoms.positions:\n",
    "    new_coords = atom_coords + t_R\n",
    "    transformed_coords.append(new_coords)\n",
    "\n",
    "substrate_6.atoms.positions = transformed_coords\n",
    "\n",
    "# Save the updated universe to a new PDB file\n",
    "output_filename = \"aligned_substrate_6.pdb\"\n",
    "substrate_6.atoms.write(output_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "md-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
